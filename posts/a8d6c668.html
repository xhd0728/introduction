<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>REPLUG: Retrieval-Augmented Black-Box Language Models - Haidong Xin</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Haidong Xin"><meta name="msapplication-TileImage" content="img/logo.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Haidong Xin"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="23年的这篇论文提出了检索增强的新范式，即REPLUG。它将语言模型当作一个黑盒子，即冻结语言模型的参数不再优化，转而去优化检索组件让检索组件来适配语言模型，以此来消除语言模型的“幻觉”，减少事实性错误的生成。 关键词：检索增强、向量检索、困惑度、幻觉、事实性错误"><meta property="og:type" content="blog"><meta property="og:title" content="REPLUG: Retrieval-Augmented Black-Box Language Models"><meta property="og:url" content="https://resume.kokomi0728.eu.org/posts/a8d6c668.html"><meta property="og:site_name" content="Haidong Xin"><meta property="og:description" content="23年的这篇论文提出了检索增强的新范式，即REPLUG。它将语言模型当作一个黑盒子，即冻结语言模型的参数不再优化，转而去优化检索组件让检索组件来适配语言模型，以此来消除语言模型的“幻觉”，减少事实性错误的生成。 关键词：检索增强、向量检索、困惑度、幻觉、事实性错误"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170615.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170709.png"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170802.png"><meta property="article:published_time" content="2023-11-30T16:00:00.000Z"><meta property="article:modified_time" content="2023-12-01T13:04:30.913Z"><meta property="article:author" content="Haidong Xin"><meta property="article:tag" content="信息检索"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170615.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://resume.kokomi0728.eu.org/posts/a8d6c668.html"},"headline":"REPLUG: Retrieval-Augmented Black-Box Language Models","image":["https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170615.png","https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170709.png","https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170802.png"],"datePublished":"2023-11-30T16:00:00.000Z","dateModified":"2023-12-01T13:04:30.913Z","author":{"@type":"Person","name":"Haidong Xin"},"publisher":{"@type":"Organization","name":"Haidong Xin","logo":{"@type":"ImageObject","url":"https://resume.kokomi0728.eu.org/posts/img/logo.png"}},"description":"23年的这篇论文提出了检索增强的新范式，即REPLUG。它将语言模型当作一个黑盒子，即冻结语言模型的参数不再优化，转而去优化检索组件让检索组件来适配语言模型，以此来消除语言模型的“幻觉”，减少事实性错误的生成。 关键词：检索增强、向量检索、困惑度、幻觉、事实性错误"}</script><link rel="canonical" href="https://resume.kokomi0728.eu.org/posts/a8d6c668.html"><link rel="alternate" href="/atom.xml" title="Haidong Xin" type="application/atom+xml"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?5ad8f086133656ac982afa9562cb247c";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-ZEK9ZMSLBS" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-ZEK9ZMSLBS');</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Haidong Xin" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/profile">Profile</a><a class="navbar-item" href="/achievement">Achievement</a><a class="navbar-item" href="/links">Link</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item copyright article-title type-1">转载</span><span class="level-item"><time dateTime="2023-11-30T16:00:00.000Z" title="2023/12/1 00:00:00">2023-12-01</time>发表</span><span class="level-item"><time dateTime="2023-12-01T13:04:30.913Z" title="2023/12/1 21:04:30">2023-12-01</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></span><span class="level-item">27 分钟读完 (大约3990个字)</span><span class="level-item" id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">REPLUG: Retrieval-Augmented Black-Box Language Models</h1><div class="copyright article-block type-1"><p>原文链接：<a href="https://mp.weixin.qq.com/s/RQlgl90QP4uJZ_y414BuMA" target="_blank">https://mp.weixin.qq.com/s/RQlgl90QP4uJZ_y414BuMA</a></p></div><div class="content"><p>23年的这篇论文提出了检索增强的新范式，即<strong>REPLUG</strong>。它将语言模型当作一个黑盒子，即冻结语言模型的参数不再优化，转而去优化检索组件让检索组件来适配语言模型，以此来消除语言模型的“幻觉”，减少事实性错误的生成。</p>
<p><strong>关键词：检索增强、向量检索、困惑度、幻觉、事实性错误</strong></p>
<span id="more"></span>

<h2 id="1-LLM的幻觉"><a href="#1-LLM的幻觉" class="headerlink" title="1. LLM的幻觉"></a>1. LLM的幻觉</h2><p><strong>GPT-3</strong>等<strong>LLM</strong>（large language models，大语言模型）能力很强，在各个任务上都有非常不错的表现。但是，在LLM强大的背后，有着很多不能被忽视的缺陷。</p>
<p>首先，<strong>LLM对资源的要求高</strong>。比如，假设我们微调BLOOM-176B，就需要72张显存为80GB的A100显卡。没钱没资源或者资源有限的我们除流下两行热泪外，也可以退而求其次，去使用一些小模型（附：GPT-1到GPT-3的参数量是越来越大，从5GB到45TB，你仔细品一品这个趋势😂）。</p>
<p>LLM的另一个问题是<strong>生成文本中的事实性错误</strong>。在闲聊场景下，大家对这种事实性错误的容忍度还比较高，顶多笑一笑，在微信上和自己的朋友嘀咕两句，或者转头跟同事调侃一下“也不过如此”而已；可是在非闲聊场景下，比如医学、金融、军事等，事实性错误就是不可容忍的。在这些场景下落地，要求通常都是非常苛刻的，否则后果难以承受。针对这个问题，我们则要想办法去消除大模型中的事实错误。</p>
<p><strong>LLM</strong>的事实性错误有一个更通用的术语叫“<strong>幻觉</strong>”（<strong>Hallucination</strong>）。“幻觉”一词最早用于图像合成等领域，后来在图像检测中用于描述检测到的虚假或错误目标等。在自然语言生成 (NLG) 任务中，“幻觉“是用来指代我们所说的”事实性错误”。</p>
<h2 id="2-检索增强范式的转变"><a href="#2-检索增强范式的转变" class="headerlink" title="2. 检索增强范式的转变"></a>2. 检索增强范式的转变</h2><h3 id="2-1-“白盒”式检索增强"><a href="#2-1-“白盒”式检索增强" class="headerlink" title="2.1 “白盒”式检索增强"></a>2.1 “白盒”式检索增强</h3><p>语言模型生成的文本自然流畅、语法正确，就像人说出来的一样。但实际上，可能毫无意义并且包含虚假信息。这样的文本以假乱真，就像人产生的幻觉一样。针对这个问题，学术界也有相应的解决办法，即<strong>检索增强</strong>。</p>
<p>其实，检索方法的重度使用区是开放域问答，近几年关于开放域问答的研究多采用<strong>信息检索+机器阅读理解二阶段范式</strong>：</p>
<ul>
<li><p>检索器从已有知识库（如维基百科等网页）中找到相关知识；</p>
</li>
<li><p>利用机器阅读理解算法从相关知识中找到问题的答案。</p>
</li>
</ul>
<p>同样地，在文本生成领域，<strong>检索增强语言模型</strong>的范式通常也包含两个步骤：</p>
<ul>
<li><p>检索器根据用户query（用户输入）从已有知识库获得相关知识；</p>
</li>
<li><p>生成器根据用户query和检索到的辅助知识进行最终预测。</p>
</li>
</ul>
<p>在以往的检索增强范式下，语言模型通常都被当作“<strong>白盒</strong>”，简单地说就是我们要么优化它们的参数（比如Atlas联合优化了检索器和语言模型），要么获得其表征。考虑到大语言模型对资源的要求，这条路线的代价是比较大的。</p>
<p>除此以外，还有一点让“白盒”的“白”不可行：很多大语言模型并没有开源。比如，我们目前只能<strong>通过网页或者OpenAI提供的API去访问</strong>ChatGPT*<em><strong>，这种未开放的大模型自然是无法微调的。在这种情形下，语言模型倒更像一个“</strong>黑盒</em>*”，我们只能喂给它们输入，然后从它们那里获得结果。</p>
<p>总的来说就是，<strong>越来越大的语言模型规模和语言模型的黑盒特性使得白盒这种检索增强范式不可行</strong>。</p>
<h3 id="2-2-“黑盒”式检索增强"><a href="#2-2-“黑盒”式检索增强" class="headerlink" title="2.2 “黑盒”式检索增强"></a>2.2 “黑盒”式检索增强</h3><p>今天我们要分享的这篇工作所提出的 <strong>REPLUG</strong> 模型可以说是<strong>“黑盒”式检索增强</strong>的代表。在这种新范式下，语言模型是一个黑盒子（它的参数被冻结了，不会被更新优化），<strong>检索组件才是可微调的部分</strong>。</p>
<p><img src="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170615.png"></p>
<p>如上图所示，简单地理解就是在“白盒”范式下，假设检索组件不优化，也就是我们确信检索组件检索到的相关文本是足够准确的，即喂给语言模型的输入文本所含的信息丰富且准确，并且对每一个用户query（用户输入）来说，检索出来的文本确定的，我们需要<strong>优化语言模型</strong>让它产生的输出更正确，也就是<strong>调节语言模型来适配检索组件</strong>；</p>
<p>当然“白盒”模式下，<strong>检索组件也可以一并优化</strong>，但是这个相应地会更复杂。因为检索组件一旦被训练，检索出的文本和用户query的表示就会改变，那么被选出来的文本也就变了。什么时候重新编码一遍所有文本又是一个待考量的问题。</p>
<p>“黑盒”范式下，语言模型的参数不会被优化，我们<strong>要优化的是检索组件</strong>从而确保检索出的知识更好，也就是给到语言模型的输入更好，这样语言模型产生的输出才更正确，也就是<strong>调节检索组件来适配语言模型</strong>。</p>
<h2 id="3-REPLUG-REPLUG-LSR"><a href="#3-REPLUG-REPLUG-LSR" class="headerlink" title="3. REPLUG &amp; REPLUG LSR"></a>3. REPLUG &amp; REPLUG LSR</h2><p><strong>RERLUG</strong>(Retrieve and Plug) 其实就是在语言模型上额外加了一个检索组件，利用检索组件获得一些相关信息，与原始输入一起作为语言模型的新输入，检索组件和语言模型都不需要训练。（个人认为某种程度上检索出来的加到原始输入即用户query上的这些文本有点像prompt）。</p>
<p><strong>RERLUG LST</strong>（RERLUG with LM-Supervised Retrieval）可以看作是 <strong>RERLUG <strong>的升级版，它</strong>利用语言模型产生监督信号，从而去优化检索组件</strong>，让检索组件倾向于挑选出能够<strong>降低语言模型所生成文本的困惑度</strong>。</p>
<h3 id="3-1-REPLUG"><a href="#3-1-REPLUG" class="headerlink" title="3.1 REPLUG"></a>3.1 REPLUG</h3><p><img src="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170709.png"></p>
<p>如上图所示，<strong>RERLUG</strong>主要包含两个步骤：</p>
<ul>
<li><p>利用<strong>检索器</strong>从外部语料库中检索出与用户query相关的文档集</p>
</li>
<li><p>接着，分别将每个文档内容与用户query拼接然后送入语言模型（并行），最后再<strong>集成</strong>预测的概率。</p>
</li>
</ul>
<p>下面，我们来分别介绍这两个核心部分。</p>
<h4 id="3-1-1-检索器"><a href="#3-1-1-检索器" class="headerlink" title="3.1.1 检索器"></a>3.1.1 检索器</h4><p><strong>REPLUG</strong> 使用 <strong>双塔结构的向量检索器</strong>（原文：a dense retriever based on the dual encoder architecture）。</p>
<p>所谓<strong>双塔&#x2F;双编码器网络</strong>其实就是将用户query和检索文档 <strong>分别编码</strong>，然后再利用 cosine 等距离函数计算二者的<strong>相似度</strong>。具体又可分为<strong>SDE</strong>（Simese dual encoder）和 <strong>ADE</strong>（Asymmetric dual encoder）：</p>
<ul>
<li><p><strong>SDE</strong>：虽说是双塔，但实际上用户query和检索文档共用一套参数，；</p>
</li>
<li><p><strong>ADE</strong>：编码用户query和检索文档的编码器共享部分参数或者完全不共享参数，是两套独立的参数网络。</p>
</li>
</ul>
<p><strong>不同于BERT等典型的交互式网络，SDE</strong> 和 <strong>ADE</strong> 的共同点是都不会进行深层交互。<strong>双塔结构一个最典型的应用是召回or粗排，也就是适用于对计算速度要求严格的场景</strong>。</p>
<p>根据论文的描述，可以知道 <strong>REPLUG <strong>采用的是</strong>SDE</strong>，即文档 $d$ 和用户query $x$ 都使用同一编码器进行向量化。具体地，在最后一层隐藏表示上利用<strong>平均池化</strong>获得文档 $d$ 的编码 $E(d)$；同理，获得输入 $x$ 的编码 $E(x)$，然后利用 <strong>cosine</strong> 计算二者相似度：</p>
<p>$$s(d,x)&#x3D;cos(E(d),E(x))$$</p>
<p>最后根据 $s(d,x)$选出 k 个最相关的文档。</p>
<p>显然，我们需要把用户query $x$ 和所有文档 $d \in D$ 比较；$D$ 是一个相当大的规模的数据，这个速度比较慢，所以 <strong>RERLUG <strong>使用了</strong>FAISS</strong>（可快速寻找k个最相似向量的系统，需要预先将所有文档编码）来加速。</p>
<h4 id="3-1-2-重构输入，加权集成概率"><a href="#3-1-2-重构输入，加权集成概率" class="headerlink" title="3.1.2 重构输入，加权集成概率"></a>3.1.2 重构输入，加权集成概率</h4><p>前面我们说过 <strong>REPLUG <strong>是分别将每个文档内容与用户query拼接，然后送入语言模型（并行），最后再</strong>集成</strong>预测的概率。那为什么要这么做呢？</p>
<p><strong>语言模型本身对输入是有限制的，输入的长度由语言模型的上下文窗口大小决定</strong>，比如GPT-3系列模型中，text-davinci-003最多可接受的输入是4000个token， text-curie-001则是2048token。所以我们不可能一股脑把检索出来的最相关的 $k$ 个文档都一次性喂给语言模型。</p>
<p>针对这个问题，<strong>REPLUG <strong>设计了一个</strong>集成策略</strong>。具体地，将每个文档 $d \in D’$ 都添加到 $x$ 的前面，再将拼接后的文本分别给到语言模型，最后将所有 $k$ 个的输出概率集成起来(这里利用了相关度加权)。这里 $D’$ 表示的就是最相关的 $k$ 个文档，集成策略的公式如下：</p>
<p>$$p(y|x,D)&#x3D;\sum\limits_{d \in D’}p(y|d \circ x) \cdot \lambda(d,x)$$</p>
<p>其中，$\circ$ 表示向量拼接，$\lambda(d,x)$ 是经过归一化的文档—用户query对的相似度：</p>
<p>$$\lambda(d,x)&#x3D;\frac{e^{s(d,x)}}{\sum_{d \in D’}e^{s(d,x)}}$$</p>
<h3 id="3-2-REPLUG-LSR"><a href="#3-2-REPLUG-LSR" class="headerlink" title="3.2 REPLUG LSR"></a>3.2 REPLUG LSR</h3><p>前文我们说，可以将 <strong>RERLUG LST</strong> 看作是 <strong>RERLUG</strong> 的升级版，它主要<strong>利用语言模型产生监督信号，从而去优化检索组件，让检索组件适配语言模型</strong>。这里面，可能大家最感兴趣的就是这个<strong>监督信号</strong>，它到底是什么，怎么来的，怎么计算的？</p>
<p>在 <strong>REPLUG LSR</strong>中，这个监督信号其实是通过“匹配检索文档的概率与语言模型输出序列的困惑度(perplexity)”而来。更直白地说，<strong>REPLUG LSR 希望检索器能够找到使得语言模型生成文本困惑度较低的文档</strong>。（这里原文使用的是likelihood，即似然。结合具体公式来看，个人认为叫概率更合适，所以下文我们都统一称为概率。）</p>
<h4 id="3-2-1-语言模型的困惑度"><a href="#3-2-1-语言模型的困惑度" class="headerlink" title="3.2.1 语言模型的困惑度"></a>3.2.1 语言模型的困惑度</h4><p>这里我们简单解释下困惑度。</p>
<p>首先<strong>语言模型</strong>不仅可以用来生成文本，本质上它提供了一种很自然的方式来<strong>估计句子的概率</strong>。<strong>越好的语言模型对于我们人类给出的一句通顺流畅的话，会给出越高的概率，这样的语言模型困惑度也就越小</strong>。简单地概括就是<strong>句子概率越大，语言模型越好，困惑度越小</strong>。</p>
<p>那么”检索器要找到使得语言模型生成文本困惑度得分较低的文档”就可以这么理解：<strong>检索器检索出来的文档 $d$ 可以提高语言模型生成答案 $y$ 的概率，并且文档的检索概率越高，语言模型生成的 $y$ 的概率也越高</strong>。</p>
<p>也就是说，<strong>REPLUG LSR</strong>的监督信号中涉及两个概率计算。</p>
<h4 id="3-2-2-概率计算"><a href="#3-2-2-概率计算" class="headerlink" title="3.2.2 概率计算"></a>3.2.2 概率计算</h4><p>首先是<strong>检索文档的概率</strong>，这个部分和前面的 $\lambda(d,x)$ 比较像，只不过多了一个<strong>缩放因子</strong>$\tau$:</p>
<p>$$P_R(d|x)&#x3D;\frac{e^{\frac{s(d,x)}{\tau}}}{\sum_{d \in D’}e^{\frac{s(d,x)}{\tau}}}$$</p>
<p>注意到，这里归一化也是在 $D’$ 上做的，所以这个归一化是<strong>近似归一化</strong>。</p>
<p>然后是<strong>语言模型输出序列的困惑度概率</strong>。假设 $P_{LM}(y|d,x)$ 计算的是在给定用户query $x$ 和检索文档 $d$ 的条件下，语言模型生成标准答案 $y$ 的概率；那么在文档集 $D$ 中，文档 $d$ 对应的语言模型输出序列的困惑度概率如下：</p>
<p>$$Q_R(d|x,y)&#x3D;\frac{e^{\frac{P_{LM}s(d,x)}{\beta}}}{\sum_{d \in D’}e^{\frac{P_{LM}s(d,x)}{\beta}}}$$</p>
<p>这里也是一个近似归一化，缩放因子为 $\beta$。</p>
<p>但是这里小喵有<strong>两个疑问</strong>：</p>
<p>(1) 如果语言模型是一个黑盒，那我们又该如何计算 $P_{LM}(y|d,x)$ 呢？</p>
<p>(2) 还有这里的并不是一个token，而是一个token序列，针对token序列前面的集成概率具体又是怎么计算的呢？</p>
<h4 id="3-2-3-损失函数"><a href="#3-2-3-损失函数" class="headerlink" title="3.2.3 损失函数"></a>3.2.3 损失函数</h4><p><img src="https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231201170802.png"></p>
<p>我们前面说过<strong>文档的检索概率越高，语言模型生成的 $y$ 的概率也越高</strong>，也就是说我们希望这两个概率一致。而度量两个<strong>概率分布的距离</strong>可以通常选用的是<strong>KL散度</strong>，所以在 <strong>REPLUG LSR</strong>中，损失函数如下：</p>
<p>$$L&#x3D;\frac{1}{X}\sum\limits_{x \in X}KL(P_R(d|x)||Q_{LM}(d|x,y))$$</p>
<p>这里 $X$ 代表用户输入的集合。这个损失函数非常容易理解，并且某种程度上只有这样才能将语言模型的输出与检索器关联起来，从而去优化检索器。</p>
<p><strong>REPLUG LSR</strong> 通过<strong>优化检索器的参数</strong>降低损失函数的值从而让检索器适配到语言模型。这里，需要注意的是前面我们提过检索组件一旦被训练，检索出的文本和用户query的表示就会改变，那么被选出来的文本也就变了。所以在训练过程中， <strong>REPLUG LSR</strong> <strong>每隔 $T$ 个 training step 就会重新编码一遍所有文本</strong>。</p>
<h2 id="4-总结"><a href="#4-总结" class="headerlink" title="4. 总结"></a>4. 总结</h2><p>今天我们分享了一篇23年的新工作，它提出了检索增强语言模型的新范式。在这个范式下，利用语言模型产生监督信号，从而去优化检索组件，让检索组件适配语言模从而消除或减少幻觉即事实性错误的生成。</p>
<p>在今天这篇文章中，小喵主要集中在论文方法和思想的分享，感兴趣的读者朋友可以下载原文详细阅读实验部分。对于小喵的疑问，有知道的朋友可以后台私信小喵，咱们一起交流一下。</p>
<h4 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h4><p>[1]</p>
<p>《REPLUG: Retrieval-Augmented Black-Box Language Models》: <em><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2301.12652.pdf">https://arxiv.org/pdf/2301.12652.pdf</a></em></p>
</div><div class="article-licensing box"><div class="licensing-title"><p>REPLUG: Retrieval-Augmented Black-Box Language Models</p><p><a href="https://resume.kokomi0728.eu.org/posts/a8d6c668.html">https://resume.kokomi0728.eu.org/posts/a8d6c668.html</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>作者</h6><p>Haidong Xin</p></div></div><div class="level-item is-narrow"><div><h6>发布于</h6><p>2023-12-01</p></div></div><div class="level-item is-narrow"><div><h6>更新于</h6><p>2023-12-01</p></div></div><div class="level-item is-narrow"><div><h6>许可协议</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/">信息检索</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/posts/23f23e19.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Universal-Guided-Diffusion</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/posts/a5e8b87b.html"><span class="level-item">COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/xdl.png" alt="辛海东"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">辛海东</p><p class="is-size-6 is-block">哈尔滨工程大学 | 计算机科学与技术学院</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Harbin, HLJ, P.R.China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">47</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">4</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/xhd0728"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/xhd0728"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Linkedin" href="https://www.linkedin.com/in/haidongxin"><i class="fa-brands fa-linkedin"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="ResearchGate" href="https://www.researchgate.net/profile/Haidong-Xin"><i class="fa-brands fa-researchgate"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fa-solid fa-rss"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto://hdxin2002@gmail.com"><i class="fa-regular fa-envelope"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#1-LLM的幻觉"><span class="level-left"><span class="level-item">1. LLM的幻觉</span></span></a></li><li><a class="level is-mobile" href="#2-检索增强范式的转变"><span class="level-left"><span class="level-item">2. 检索增强范式的转变</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#2-1-“白盒”式检索增强"><span class="level-left"><span class="level-item">2.1 “白盒”式检索增强</span></span></a></li><li><a class="level is-mobile" href="#2-2-“黑盒”式检索增强"><span class="level-left"><span class="level-item">2.2 “黑盒”式检索增强</span></span></a></li></ul></li><li><a class="level is-mobile" href="#3-REPLUG-REPLUG-LSR"><span class="level-left"><span class="level-item">3. REPLUG &amp; REPLUG LSR</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#3-1-REPLUG"><span class="level-left"><span class="level-item">3.1 REPLUG</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#3-1-1-检索器"><span class="level-left"><span class="level-item">3.1.1 检索器</span></span></a></li><li><a class="level is-mobile" href="#3-1-2-重构输入，加权集成概率"><span class="level-left"><span class="level-item">3.1.2 重构输入，加权集成概率</span></span></a></li></ul></li><li><a class="level is-mobile" href="#3-2-REPLUG-LSR"><span class="level-left"><span class="level-item">3.2 REPLUG LSR</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#3-2-1-语言模型的困惑度"><span class="level-left"><span class="level-item">3.2.1 语言模型的困惑度</span></span></a></li><li><a class="level is-mobile" href="#3-2-2-概率计算"><span class="level-left"><span class="level-item">3.2.2 概率计算</span></span></a></li><li><a class="level is-mobile" href="#3-2-3-损失函数"><span class="level-left"><span class="level-item">3.2.3 损失函数</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="#4-总结"><span class="level-left"><span class="level-item">4. 总结</span></span></a><ul class="menu-list"><ul class="menu-list"><li><a class="level is-mobile" href="#参考资料"><span class="level-left"><span class="level-item">参考资料</span></span></a></li></ul></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://xhd0728.github.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Scholar Homepage</span></span><span class="level-right"><span class="level-item tag">xhd0728.github.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%8E%A8%E6%96%87/"><span class="level-start"><span class="level-item">公众号推文</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%B7%A5%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">工程项目</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%8A%80%E6%9C%AF%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">技术学习</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">论文学习</span></span><span class="level-end"><span class="level-item tag">32</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-04T16:00:00.000Z">2023-12-05</time></p><p class="title"><a href="/posts/b324fdd1.html">【一院一节】第二届“贡橙杯”CTF竞赛圆满落幕</a></p><p class="categories"><a href="/categories/%E5%85%AC%E4%BC%97%E5%8F%B7%E6%8E%A8%E6%96%87/">公众号推文</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-12-01T16:00:00.000Z">2023-12-02</time></p><p class="title"><a href="/posts/23f23e19.html">Universal-Guided-Diffusion</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-30T16:00:00.000Z">2023-12-01</time></p><p class="title"><a href="/posts/a8d6c668.html">REPLUG: Retrieval-Augmented Black-Box Language Models</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-24T16:00:00.000Z">2023-11-25</time></p><p class="title"><a href="/posts/a5e8b87b.html">COCO-LM: Correcting and Contrasting Text Sequences for Language Model Pretraining</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-11-22T16:00:00.000Z">2023-11-23</time></p><p class="title"><a href="/posts/e65f4108.html">字节对编码(BPE)</a></p><p class="categories"><a href="/categories/%E8%AE%BA%E6%96%87%E5%AD%A6%E4%B9%A0/">论文学习</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">47</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/C-C/"><span class="tag">C/C++</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CCSP/"><span class="tag">CCSP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CTF/"><span class="tag">CTF</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">17</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BA%94%E5%9B%9B%E6%9D%AF/"><span class="tag">五四杯</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2/"><span class="tag">信息检索</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"><span class="tag">后端开发</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%93%B2%E5%AD%A6/"><span class="tag">哲学</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"><span class="tag">嵌入式</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%B7%A5%E7%A8%8B%E9%A1%B9%E7%9B%AE/"><span class="tag">工程项目</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B/"><span class="tag">扩散模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E5%AD%A6/"><span class="tag">数学</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91/"><span class="tag">机器翻译</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"><span class="tag">概率论</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"><span class="tag">线性代数</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/"><span class="tag">计算机视觉</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B/"><span class="tag">预训练模型</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start" style="display: flex"><div class="is-size-7"><span>&copy; 2023 Haidong Xin</span>  |  <a>港ICP备20230101号-1</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客, <span id="busuanzi_value_site_pv">0</span>次访问</span></div></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>