- 本周工作
	- 学习Teacher-Student模型
	- 调研数据集
		- CSQA: CommonsenseQA 2.0 数据集包含 14,343 个关于日常常识知识的是/否问题（或断言）。该数据集是通过游戏化收集的，游戏玩家的目标是使用特定短语提出误导竞争对手人工智能的问题。这种游戏环境提高了用户参与度，同时让游戏设计者能够控制所收集的数据，使我们能够大规模收集高质量的数据。
		- StrategyQA: StrategyQA 是一个专注于开放领域问题的问答基准，其中所需的推理步骤隐含在问题中，并且应该使用策略来推断。StrategyQA 包括 2,780 个示例，每个示例都包含一个策略问题、其分解和证据段落。
		- QUEST: 这是一个包含 3357 个具有隐式集合操作的自然语言查询的数据集，映射到与维基百科文档相对应的一组实体。该数据集挑战模型将查询中提到的多个约束与文档中的相应证据相匹配，并正确执行各种集合操作。该数据集是使用维基百科类别名称半自动构建的。查询由各个类别自动组成，然后由众包人员进行解释并进一步验证其自然性和流畅性。
	- 读论文 Chain-of-Verification Reduces Hallucination in Large Language Models（验证链）
		- 生成基线响应：给定一个查询，使用LLM生成响应。
		- 计划验证：给定查询和基线响应，生成一个验证问题列表，帮助自我分析原始响应中是否有任何错误。
		- 执行验证：依次回答每个验证问题，然后对照原始回答检查答案，以检查不一致或错误。
			- **joint**: 计划和执行（步骤2和3）通过使用单个LLM提示符来完成，由此少数镜头演示包括验证问题及其紧接在问题之后的答案。在这种方法中，不需要单独的提示。
			- **2-step**: 将计划和执行分成不同的步骤，两者都有自己的LLM提示符。在第一步中，计划提示基线响应条件。从计划中产生的验证问题在第二步中得到回答，关键是给LLM提示的上下文只包含问题，而不包含原始基线响应，因此不能直接重复这些答案。
			- **factored**: 将所有问题作为单独的提示独立回答。虽然这可能在计算上更昂贵，需要执行更多的LLM提示，但它们可以并行运行，因此可以批处理。
			- **factor+revise**: 通过一个额外的LLM提示符将此作为一个有意的步骤来执行，这可能会使最终系统更容易明确地对此步骤进行推理。
		- 生成最终验证响应：给定发现的不一致之处（如果有），生成包含验证结果的修订响应。
		- ![image.png|500](https://cdn.jsdelivr.net/gh/xhd0728/oss-github-picgo-repository/picgo/20231212143512.png)
	- 综述: Survey of Hallucination in Natural Language Generation
