---
title: L1正则化
tag:
  - 数学
  - 机器学习
category:
  - 论文学习
lang: zh-CN
abbrlink: 18e73c3c
date: 2023-11-13 00:00:00
---

L1正则化是一种在机器学习中用于降低模型复杂度的技术。它通过向模型的损失函数添加L1范数（向量中各元素绝对值的和）的惩罚来实现。L1正则化的目的是促使模型学习到稀疏权重，即让一些特征对应的权重变为零，从而减少模型的复杂性。
<!--more-->
对于一个线性回归模型，L1正则化的损失函数可以写成：

$$ J(\theta) = \text{MSE}(\theta) + \lambda \sum_{i=1}^{n} | \theta_i | $$

其中：
- $J(\theta)$ 是带有L1正则化的损失函数；
- $\text{MSE}(\theta)$ 是均方误差（Mean Squared Error）损失函数，用于衡量模型的预测与实际值之间的差距；
- $\lambda$ 是正则化强度，控制着正则化对总损失的影响；
- $\sum_{i=1}^{n} | \theta_i |$ 是模型权重向量 \(\theta\) 中所有权重的绝对值之和。

L1正则化的效果是，一些特征对应的权重会变为零，从而达到特征选择（feature selection）的效果。这使得模型更加简单，减少了过拟合的风险，并提高了模型的泛化能力。

在深度学习中，L1正则化同样可以应用于神经网络的权重，通过控制权重的稀疏性来提高模型的泛化性能。在实践中，通常使用梯度下降等优化算法来最小化包含L1正则项的损失函数。